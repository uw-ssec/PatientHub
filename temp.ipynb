{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "with open(\"src/config/agents.yaml\") as stream:\n",
    "    try:\n",
    "        config = yaml.safe_load(stream)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Uncover cutting-edge developments in AI safety\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke([\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "                {\"role\": \"user\", \"content\": \"hello\"},\n",
    "            ])\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers.openai_functions import PydanticOutputFunctionsParser\n",
    "\n",
    "class PatientResponse(BaseModel):\n",
    "    reasoning: str = Field(description=\"reason about your thoughts and feelings\")\n",
    "    emotion: str = Field(description=\"Current emotion. Could be either sad/angry/happy\")\n",
    "    response: str = Field(description=\"Your generated response\")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    base_url=\"http://115.182.62.174:18888/v1\",\n",
    "    api_key=\"\",\n",
    "    temperature=0.6,\n",
    ").with_structured_output(PatientResponse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Respond to the human therapist.\"),\n",
    "    (\"human\", \"{input_text}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reasoning': \"I've been feeling overwhelmed with work and personal commitments, and it's starting to affect my mood and energy levels. I could use some guidance on how to manage these feelings and find a better balance.\", 'emotion': 'sad', 'response': \"I've been feeling a bit overwhelmed lately. There's a lot going on with work and my personal life, and I'm struggling to keep up. I think it's starting to affect my mood and how I feel overall. I'm hoping you might have some advice on how to manage these feelings and find a better balance.\"}\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke([\n",
    "                {\"role\": \"system\", \"content\": \"Respond to the human therapist.\"},\n",
    "                {\"role\": \"user\", \"content\": \"How may I help you today?\"},\n",
    "            ])\n",
    "print(response.model_dump())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reasoning=\"I've been feeling overwhelmed with my work responsibilities and personal life. It feels like I can't catch a break and I'm constantly stressed out.\" emotion='sad' response=\"I've been feeling really overwhelmed recently with work and personal stuff. It's like there's always something going on that needs my attention, and I can't seem to find a moment to relax. I think I could use some help figuring out how to manage all these responsibilities without feeling so stressed all the time.\"\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | llm \n",
    "result = chain.invoke({\"input_text\": \"How may I help you today?\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reasoning': \"I've been feeling overwhelmed with work and personal commitments, and it's starting to affect my mood and energy levels. I could use some guidance on how to manage these feelings and find a better balance.\",\n",
       " 'emotion': 'sad',\n",
       " 'response': \"I've been feeling a bit overwhelmed lately. There's a lot going on with work and my personal life, and I'm struggling to keep up. I think it's starting to affect my mood and how I feel overall. I'm hoping you might have some advice on how to manage these feelings and find a better balance.\"}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "  base_url=\"https://openrouter.ai/api/v1\",\n",
    "  api_key=\"\",\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"qwen/qwen3-235b-a22b:free\",\n",
    "  # model=\"google/gemini-2.5-pro-exp-03-25\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Hello\"\n",
    "    }\n",
    "  ]\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, the user said \"Hello\". That's a greeting. I should respond politely. Let me make sure to greet them back and offer help. Maybe say something like \"Hello! How can I assist you today?\" Keep it friendly and open-ended so they feel comfortable asking anything. Double-check for any typos or errors. Yep, that looks good. Ready to send.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(completion.choices[0].message.reasoning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello world'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"hello world\"\n",
    "text.capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"emotion\": {\"description\": \"Current emotion. Could be either sad/angry/happy\", \"title\": \"Emotion\", \"type\": \"string\"}, \"response\": {\"description\": \"Your generated response\", \"title\": \"Response\", \"type\": \"string\"}}, \"required\": [\"emotion\", \"response\"]}\\n```'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Dict\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "\n",
    "\n",
    "class PatientResponse(BaseModel):\n",
    "    emotion: str = Field(description=\"Current emotion. Could be either sad/angry/happy\")\n",
    "    response: str = Field(description=\"Your generated response\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "parser.get_format_instructions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(\".env\")\n",
    "\n",
    "client = ChatOpenAI(\n",
    "    model=os.environ.get(\"MODEL_NAME\"),\n",
    "    base_url=os.environ.get(\"API_URL\"),\n",
    "    api_key=os.environ.get(\"API_KEY\"),\n",
    "    temperature=0.6,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today? ðŸ˜Š', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 75, 'prompt_tokens': 19, 'total_tokens': 94, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'qwen/qwen3-30b-a3b:free', 'system_fingerprint': None, 'id': 'gen-1746084411-b4b9H6hTU0bPaow7sXBr', 'finish_reason': 'stop', 'logprobs': None}, id='run-84829f07-e165-40c0-94a5-e7bc20df5eb8-0', usage_metadata={'input_tokens': 19, 'output_tokens': 75, 'total_tokens': 94, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.invoke([{\"role\": \"system\", \"content\": \"You are a helpful assistant\"}, {\"role\": \"user\", \"content\": \"hello\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
